{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenclements/praxis/blob/main/practice2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "lN5-AcoypUan",
        "outputId": "9415a181-a9d1-42ac-ed88-797027dc3ef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 24 02:46:22 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sI_JO6jFrD7Z",
        "outputId": "313b6a3d-002c-402f-a47d-d771f1c409e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "oWRDK3jhrlOB",
        "outputId": "85a993d0-0b1e-4b43-b12a-172a6663b764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SpDcPu8tmmK0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oR_xocCCmmK3"
      },
      "outputs": [],
      "source": [
        "#email = pd.read_csv('../../../../../../data/r4.2/email.csv')\n",
        "file = pd.read_csv('/content/drive/MyDrive/Praxis/data/file.csv')\n",
        "#http = pd.read_csv('../../../../../../data/r4.2/http.csv')\n",
        "#logon = pd.read_csv('../../../../../../data/r4.2/logon.csv')\n",
        "#device = pd.read_csv('../../../../../../data/r4.2/device.csv')\n",
        "#tweets = pd.read_csv('/content/drive/MyDrive/Praxis/code/tweets.csv')\n",
        "#enron = pd.read_csv('../../../../../../data/praxis/ENRON/emails_enron.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SY2A5e_AmmK5"
      },
      "outputs": [],
      "source": [
        "#files = [file,email,http,logon,device]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qKGplELJmmK5",
        "outputId": "5dc06192-dad1-4af8-84df-b00778e2e249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(445581, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#for x in files:\n",
        "#    print(x.shape)\n",
        "file.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To4VNA9ymmK6",
        "outputId": "cada510a-ca4d-4962-907a-9aa7ed83cbb1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whiQkFzlmmK7"
      },
      "outputs": [],
      "source": [
        "named_params = list(model.named_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzPan1nKmmK7"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzU1LQmfmmK8",
        "outputId": "4ab180e2-1576-4e20-85e9-5abd22de4545"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 6358, 2003, 1996, 2190, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.encode_plus('Ken is the best!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcLsaWc0mmK8"
      },
      "outputs": [],
      "source": [
        "response = model(torch.tensor(tokenizer.encode('Ken is the best')).unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pcU5WijmmK8",
        "outputId": "bf759646-4594-4a8d-f177-02b724a48ce8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1575,  0.1448, -0.0683,  ..., -0.2043,  0.2934,  0.2390],\n",
              "         [ 0.0336, -0.8281, -0.0863,  ..., -0.4555,  0.7815,  0.0969],\n",
              "         [-0.3097, -0.4105,  0.0555,  ...,  0.0817,  0.9685,  0.6817],\n",
              "         [-0.6090, -0.9053, -0.0094,  ..., -0.2928,  1.2827, -0.1907],\n",
              "         [-0.8572, -0.4660, -0.3183,  ...,  0.8195,  0.9794, -0.5100],\n",
              "         [ 0.8410,  0.0964, -0.0524,  ...,  0.0601, -0.5761, -0.3895]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8167, -0.2347,  0.4112,  0.5842, -0.2368, -0.0547,  0.8562,  0.1426,\n",
              "          0.2936, -0.9997,  0.1450,  0.0200,  0.9754, -0.2654,  0.9061, -0.5125,\n",
              "         -0.0333, -0.4753,  0.2095, -0.6647,  0.5949,  0.9258,  0.6194,  0.2113,\n",
              "          0.3049,  0.1423, -0.4651,  0.8916,  0.9368,  0.6442, -0.5724,  0.1174,\n",
              "         -0.9778, -0.1278,  0.3968, -0.9710,  0.1264, -0.6902,  0.0774,  0.0675,\n",
              "         -0.8322,  0.1926,  0.9963, -0.6426, -0.1761, -0.2343, -0.9997,  0.1769,\n",
              "         -0.8348, -0.3415, -0.2471, -0.5831,  0.0996,  0.2731,  0.3361,  0.3764,\n",
              "         -0.1696, -0.0169, -0.0653, -0.4338, -0.5316,  0.2223,  0.1569, -0.8609,\n",
              "         -0.4000, -0.5648, -0.0290, -0.1551,  0.0174, -0.1103,  0.8032,  0.1094,\n",
              "          0.3877, -0.7563, -0.4657,  0.1161, -0.3904,  1.0000, -0.2348, -0.9676,\n",
              "         -0.2294, -0.3188,  0.2252,  0.6705, -0.5125, -1.0000,  0.1561, -0.0646,\n",
              "         -0.9839,  0.1469,  0.2228, -0.1413, -0.5115,  0.3427, -0.0870, -0.0302,\n",
              "         -0.1670,  0.3203, -0.1017,  0.0312, -0.0394, -0.1250,  0.0472, -0.2820,\n",
              "          0.0959, -0.3310, -0.3450,  0.1855, -0.3468,  0.6058,  0.2427, -0.2189,\n",
              "          0.2600, -0.9349,  0.5834, -0.1706, -0.9720, -0.3800, -0.9818,  0.6229,\n",
              "          0.0366, -0.0199,  0.9564,  0.5312,  0.2151,  0.0866,  0.4216, -1.0000,\n",
              "         -0.2497, -0.0239,  0.1821, -0.0255, -0.9654, -0.9313,  0.3684,  0.9427,\n",
              "          0.0948,  0.9943, -0.0994,  0.8976,  0.2936,  0.0337, -0.4188, -0.3167,\n",
              "          0.2703,  0.2657, -0.5170,  0.2313,  0.0477, -0.2670, -0.0363, -0.2155,\n",
              "          0.3870, -0.9116, -0.3264,  0.9120,  0.3989,  0.3585,  0.7035, -0.1710,\n",
              "         -0.2568,  0.7380,  0.2287,  0.2560,  0.0076,  0.2603, -0.2587,  0.4150,\n",
              "         -0.7829,  0.3344,  0.3150, -0.0657,  0.3772, -0.9641, -0.2078,  0.3035,\n",
              "          0.9805,  0.7210,  0.1508, -0.1584, -0.2147, -0.0291, -0.9147,  0.9672,\n",
              "         -0.0520,  0.2321,  0.5270, -0.3114, -0.7996, -0.5140,  0.7923, -0.0705,\n",
              "         -0.7913,  0.0682, -0.3634, -0.3205,  0.2547,  0.2639, -0.2118, -0.3611,\n",
              "          0.0353,  0.9023,  0.9375,  0.7099, -0.6481,  0.3987, -0.8610, -0.3304,\n",
              "          0.0612,  0.2041,  0.0480,  0.9870,  0.0348, -0.0780, -0.8888, -0.9753,\n",
              "         -0.0425, -0.8425,  0.0660, -0.5718,  0.2351,  0.5516, -0.1355,  0.3071,\n",
              "         -0.9730, -0.7336,  0.2907, -0.1506,  0.3196, -0.1573,  0.1899, -0.1894,\n",
              "         -0.5207,  0.7245,  0.8405,  0.4957, -0.6608,  0.7082, -0.2192,  0.8264,\n",
              "         -0.5279,  0.9588, -0.1515,  0.2705, -0.9111,  0.3592, -0.8634,  0.2711,\n",
              "         -0.0159, -0.6635, -0.2433,  0.3435,  0.1794,  0.8391, -0.3704,  0.9916,\n",
              "         -0.2869, -0.9255,  0.4190, -0.0400, -0.9776, -0.2256,  0.1604, -0.6210,\n",
              "         -0.2514, -0.2768, -0.9354,  0.8204,  0.0400,  0.9761,  0.0483, -0.8631,\n",
              "         -0.0999, -0.8725, -0.2006, -0.0148,  0.6456, -0.1402, -0.9328,  0.3868,\n",
              "          0.5202,  0.3246,  0.5521,  0.9904,  0.9976,  0.9632,  0.8522,  0.8042,\n",
              "         -0.8014,  0.1020,  0.9999, -0.2824, -0.9999, -0.9099, -0.4178,  0.3746,\n",
              "         -1.0000, -0.0073,  0.0657, -0.8795, -0.4417,  0.9657,  0.9787, -1.0000,\n",
              "          0.8241,  0.9110, -0.4161,  0.1016, -0.0438,  0.9521,  0.1379,  0.3310,\n",
              "         -0.0545,  0.2120,  0.0138, -0.7989,  0.4566,  0.4176,  0.4907,  0.0663,\n",
              "         -0.5441, -0.9080, -0.2812, -0.0559, -0.3449, -0.9392, -0.0999, -0.4006,\n",
              "          0.4287,  0.0501,  0.1275, -0.7072,  0.0739, -0.7254,  0.3419,  0.4751,\n",
              "         -0.8681, -0.5708,  0.1681, -0.5698,  0.3238, -0.9348,  0.9574, -0.1811,\n",
              "         -0.2506,  1.0000, -0.4020, -0.8126,  0.2528,  0.0731,  0.2470,  1.0000,\n",
              "          0.2287, -0.9661, -0.2957,  0.1173, -0.3206, -0.2561,  0.9960, -0.1097,\n",
              "          0.2778,  0.4429,  0.9538, -0.9826,  0.1202, -0.8940, -0.9472,  0.9532,\n",
              "          0.8998,  0.0276, -0.4487,  0.0173,  0.2500,  0.1490, -0.9331,  0.4384,\n",
              "          0.4182, -0.0966,  0.8572, -0.8252, -0.3358,  0.3466,  0.2604,  0.4668,\n",
              "         -0.2359,  0.4252, -0.1116,  0.0289, -0.2089,  0.0370, -0.9507, -0.1508,\n",
              "          1.0000,  0.1661, -0.5051, -0.0498, -0.0985, -0.3292,  0.2911,  0.3424,\n",
              "         -0.1998, -0.7357, -0.3248, -0.8974, -0.9774,  0.6261,  0.1886, -0.1696,\n",
              "          0.9970,  0.2187,  0.1313, -0.2120,  0.1336, -0.0426,  0.4108, -0.4914,\n",
              "          0.9568, -0.1668,  0.3085,  0.7461,  0.3578, -0.2654, -0.5631,  0.0193,\n",
              "         -0.8686,  0.1725, -0.9403,  0.9445, -0.3582,  0.2137,  0.0066, -0.2147,\n",
              "          1.0000,  0.2331,  0.3828, -0.3445,  0.7699, -0.7662, -0.7039, -0.2768,\n",
              "          0.0159,  0.4384, -0.1712,  0.1144, -0.9508, -0.3992, -0.2468, -0.9565,\n",
              "         -0.9826,  0.6545,  0.7092,  0.0233, -0.2306, -0.4419, -0.5491,  0.0797,\n",
              "         -0.0353, -0.9226,  0.6212, -0.1727,  0.3241, -0.1581,  0.3381, -0.4666,\n",
              "          0.8496,  0.5017,  0.0906, -0.0291, -0.7193,  0.6918, -0.7131,  0.2209,\n",
              "         -0.1046,  1.0000, -0.1508, -0.2201,  0.6579,  0.5128,  0.0473,  0.1614,\n",
              "         -0.3860,  0.0310,  0.5468,  0.5701, -0.5799, -0.2413,  0.4310, -0.4147,\n",
              "         -0.4725,  0.7100,  0.0019, -0.0421,  0.0603,  0.0193,  0.9968, -0.0238,\n",
              "          0.0944, -0.3538,  0.0993, -0.1844, -0.3545,  0.9999,  0.2055, -0.2105,\n",
              "         -0.9809,  0.0892, -0.8811,  0.9933,  0.7350, -0.7867,  0.1988,  0.2259,\n",
              "         -0.1162,  0.5584, -0.1232, -0.2103,  0.0511,  0.1178,  0.9443, -0.3177,\n",
              "         -0.9398, -0.4654,  0.2477, -0.9255,  0.8623, -0.3907, -0.0778, -0.1535,\n",
              "          0.3173,  0.6682, -0.1188, -0.9682, -0.1348, -0.0659,  0.9523,  0.1368,\n",
              "         -0.3203, -0.8837, -0.4790, -0.2707,  0.3973, -0.9060,  0.9532, -0.9683,\n",
              "          0.2439,  0.9999,  0.2650, -0.6347,  0.1010, -0.2975,  0.1697,  0.1956,\n",
              "          0.4694, -0.9353, -0.1165, -0.0619,  0.1895, -0.0894,  0.3500,  0.6258,\n",
              "          0.1272, -0.3200, -0.4504,  0.0210,  0.3409,  0.5947, -0.1914, -0.0223,\n",
              "          0.0044, -0.0333, -0.8729, -0.2106, -0.1439, -0.9603,  0.5833, -1.0000,\n",
              "         -0.4414, -0.5421, -0.1286,  0.7380,  0.1363, -0.0753, -0.6617,  0.3934,\n",
              "          0.8114,  0.6797, -0.0923,  0.1838, -0.6390,  0.0473, -0.0543,  0.1610,\n",
              "          0.3059,  0.6418, -0.0669,  1.0000,  0.0630, -0.3429, -0.9300,  0.2223,\n",
              "         -0.1546,  0.9992, -0.8567, -0.9168,  0.2350, -0.3274, -0.7203,  0.1587,\n",
              "         -0.1064, -0.5555,  0.0747,  0.9295,  0.7812, -0.3567,  0.2748, -0.1475,\n",
              "         -0.3668,  0.0148, -0.3015,  0.9757,  0.1358,  0.8344,  0.5958,  0.1476,\n",
              "          0.9465,  0.0422,  0.5329,  0.0630,  1.0000,  0.2014, -0.8837,  0.5199,\n",
              "         -0.9771, -0.0261, -0.9341,  0.2098, -0.0429,  0.8231, -0.1607,  0.9280,\n",
              "          0.4323,  0.0069,  0.2229,  0.7047,  0.1965, -0.8857, -0.9759, -0.9795,\n",
              "          0.1500, -0.3669,  0.0594,  0.1835,  0.0872,  0.2561,  0.2954, -0.9999,\n",
              "          0.8817,  0.3620, -0.3700,  0.9449,  0.0051,  0.0822,  0.1580, -0.9744,\n",
              "         -0.9500, -0.2558, -0.2463,  0.6276,  0.4966,  0.7859,  0.2695, -0.4167,\n",
              "         -0.1329,  0.5596, -0.2187, -0.9859,  0.3411,  0.3739, -0.9297,  0.9384,\n",
              "         -0.5486, -0.1026,  0.6742,  0.2676,  0.8968,  0.6660,  0.3784,  0.1015,\n",
              "          0.3193,  0.8300,  0.9197,  0.9774,  0.3066,  0.6917,  0.3982,  0.3063,\n",
              "          0.2139, -0.9096,  0.0197, -0.1434, -0.0132,  0.1552, -0.1586, -0.9256,\n",
              "          0.2899, -0.0829,  0.4318, -0.3374,  0.2491, -0.2844, -0.0855, -0.5865,\n",
              "         -0.2738,  0.4618,  0.2347,  0.8827,  0.2216,  0.0421, -0.4814, -0.0262,\n",
              "          0.3791, -0.8867,  0.8594,  0.0612,  0.5765, -0.3028, -0.0880,  0.5101,\n",
              "         -0.2842, -0.3382, -0.2247, -0.6645,  0.7904, -0.0164, -0.3756, -0.2979,\n",
              "          0.4806,  0.2432,  0.9266,  0.2117,  0.2451, -0.0413, -0.2122,  0.2580,\n",
              "         -0.2164, -0.9999,  0.3163,  0.3271, -0.3052,  0.2321, -0.3387,  0.2180,\n",
              "         -0.9484, -0.0919, -0.2944, -0.4260, -0.4485, -0.1566,  0.2999,  0.4163,\n",
              "          0.0566,  0.8476,  0.1979,  0.6753,  0.4139,  0.2863, -0.5414,  0.8514]],\n",
              "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKi4zIe5mmK9",
        "outputId": "99ee1f2c-b659-4c0a-d9e2-9b7b6df949b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.pooler_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85sLYVbxmmK9",
        "outputId": "9986663e-ce38-48e4-e165-f138e22374b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertPooler(\n",
              "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (activation): Tanh()\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.pooler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tTmJxZemmK-"
      },
      "outputs": [],
      "source": [
        "cls_embedding = response.last_hidden_state[:, 0, :].unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmghVIuzmmK-",
        "outputId": "d113a5b9-1292-4df5-89ed-f947b33ce92d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 768])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cls_embedding.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP7-j491mmK-",
        "outputId": "fb4167d3-b05a-4b24-cd9e-555f5a2efa01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.pooler(cls_embedding).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_VeWE5BmmK_",
        "outputId": "ba04ce53-5e31-4e64-d8f7-a3e883500730"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(model.pooler(cls_embedding) == response.pooler_output).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX8dZJ19mmK_",
        "outputId": "af68ba8d-3329-44b3-9e1e-39119fbceebc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'sinan' in tokenizer.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmeRIJtJmmK_"
      },
      "outputs": [],
      "source": [
        "i=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puOMJlEZmmK_"
      },
      "outputs": [],
      "source": [
        "while i < 10:\n",
        "    encoded_file_content = tokenizer.encode(file['content'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MzOVpsXmmLA",
        "outputId": "76a1f28f-8861-4be1-b07e-d3916d278835"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2673486"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd8MQltNmmLA",
        "outputId": "0fc75589-7f17-46c3-f19b-dcb70455b562"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[101,\n",
              " 1040,\n",
              " 2692,\n",
              " 1011,\n",
              " 12935,\n",
              " 1011,\n",
              " 2340,\n",
              " 1011,\n",
              " 1041,\n",
              " 2692,\n",
              " 1011,\n",
              " 17350,\n",
              " 1011,\n",
              " 29491,\n",
              " 1011,\n",
              " 20720,\n",
              " 1011,\n",
              " 1041,\n",
              " 2487,\n",
              " 2350,\n",
              " 2150,\n",
              " 2116,\n",
              " 2230,\n",
              " 4265,\n",
              " 3225,\n",
              " 15175,\n",
              " 4789,\n",
              " 28740,\n",
              " 2015,\n",
              " 8198,\n",
              " 18778,\n",
              " 21662,\n",
              " 2717,\n",
              " 2125,\n",
              " 4810,\n",
              " 2070,\n",
              " 2021,\n",
              " 2456,\n",
              " 2633,\n",
              " 2757,\n",
              " 5883,\n",
              " 2570,\n",
              " 1039,\n",
              " 4198,\n",
              " 5797,\n",
              " 2952,\n",
              " 9037,\n",
              " 5550,\n",
              " 16232,\n",
              " 2207,\n",
              " 14712,\n",
              " 2207,\n",
              " 2043,\n",
              " 4653,\n",
              " 2853,\n",
              " 11397,\n",
              " 4078,\n",
              " 8586,\n",
              " 9250,\n",
              " 8494,\n",
              " 3149,\n",
              " 2332,\n",
              " 2264,\n",
              " 6368,\n",
              " 2590,\n",
              " 2612,\n",
              " 2024,\n",
              " 4746,\n",
              " 2372,\n",
              " 2789,\n",
              " 6926,\n",
              " 102]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_file_content[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWGNoYw8mmLA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.15 ('praxis-clements')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0e4ed65ac9cd06e325be5e4053efe5dbb28567580420031f65d0d231df994926"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}